{
 "cells": [
  {
   "cell_type": "code",
   "id": "d804b424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T00:10:06.038132Z",
     "start_time": "2026-02-17T00:10:05.973001Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "order = {\n",
    "    \"items\": [],\n",
    "    \"cost\": 0.0\n",
    "}\n",
    "item = {\n",
    "    \"name\": \"\",\n",
    "    \"size\": \"\",\n",
    "    \"quantity\": 1,\n",
    "    \"modifiers\": []\n",
    "}\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df['words'] = df.iloc[:, 1].str.split()\n",
    "\n",
    "print(df['words'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [Lemme, get, one, tall, Strawberry, Smoothie, ...\n",
      "1      [I'd, like, to, order, single, trenta, espress...\n",
      "2      [Could, I, have, single, trenta, mocha, plus, ...\n",
      "3                     [Grab, me, four, avocado, toasts.]\n",
      "4      [I'm, craving, couple, of, VENTI, frappe, (moc...\n",
      "                             ...                        \n",
      "495    [May, I, get, two, Tall, iced, coffees, includ...\n",
      "496    [I'm, feeling, like, four, trenta, flat, white...\n",
      "497    [Start, me, off, with, couple, of, tall, Flat,...\n",
      "498    [Grab, me, two, short, like, Cold, Brews..., w...\n",
      "499    [I'm, feeling, like, a, Blueberry, Muffin..., ...\n",
      "Name: words, Length: 500, dtype: object\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "e11de393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:53:20.984850Z",
     "start_time": "2026-02-16T23:53:20.415719Z"
    }
   },
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyA_e0KQ-mTBsJ73_qCuLnuXvpVuv7V-C5k\")\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
    "response = model.generate_content(\"Say hello\")\n",
    "print(response.text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today?\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Barista Bench: LLM-based Order Parser\n",
    "### Uses Google Gemini to parse natural language coffee orders."
   ],
   "id": "3962ee730d183cb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T00:10:08.485783Z",
     "start_time": "2026-02-17T00:10:08.475958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from tqdm import tqdm"
   ],
   "id": "dd2dd9d95d7297e3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Load Data",
   "id": "ea12d0c476ac3d3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:55:35.955178Z",
     "start_time": "2026-02-16T23:55:35.880936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ],
   "id": "1831a05576bc6277",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (500, 3)\n",
      "Test shape: (3500, 2)\n",
      "\n",
      "Train columns: ['id', 'order', 'expected_json']\n",
      "Test columns: ['id', 'order']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Analyze Tracking Data To Build Menu And Pricing",
   "id": "e3b1d5dc10099ebc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:58:24.466527Z",
     "start_time": "2026-02-16T23:58:24.388303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_items = []\n",
    "for _, row in train_df.iterrows():\n",
    "    try:\n",
    "        data = json.loads(row['expected_json'])\n",
    "        for item in data.get('items', []):\n",
    "            all_items.append(item)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "items_df = pd.json_normalize(all_items)\n",
    "print(f\"Total item entries in training: {len(items_df)}\")\n",
    "print(f\"Unique item names: {sorted(items_df['name'].unique())}\")\n",
    "print(f\"Unique sizes: {sorted(items_df['size'].dropna().unique())}\")\n",
    "\n",
    "all_modifiers = set()\n",
    "for mods in items_df['modifiers']:\n",
    "    if isinstance(mods, list):\n",
    "        all_modifiers.update(mods)\n",
    "print(f\"Unique modifiers: {sorted(all_modifiers)}\")"
   ],
   "id": "3f8a366d3c28900f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total item entries in training: 1144\n",
      "Unique item names: ['Americano', 'Avocado Toast', 'Bacon Gouda Sandwich', 'Bagel', 'Blueberry Muffin', 'Butter Croissant', 'Cappuccino', 'Caramel Macchiato', 'Chai Latte', 'Cold Brew', 'Drip Coffee', 'Earl Grey Tea', 'Espresso', 'Flat White', 'Frappe (Coffee)', 'Frappe (Mocha)', 'Green Tea', 'Hot Chocolate', 'Iced Coffee', 'Latte', 'Matcha Latte', 'Mocha', 'Strawberry Smoothie']\n",
      "Unique sizes: ['Grande', 'Short', 'Tall', 'Trenta', 'Venti']\n",
      "Unique modifiers: ['Almond Milk', 'Breve', 'Caramel Drizzle', 'Caramel Syrup', 'Classic Syrup', 'Coconut Milk', 'Cold Foam', 'Extra Hot', 'Extra Shot', 'Hazelnut Syrup', 'Light Ice', 'No Ice', 'No Whip', 'Oat Milk', 'Peppermint Syrup', 'Skim Milk', 'Soy Milk', 'Sugar Free Vanilla', 'Vanilla Syrup', 'Whip Cream']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Build Price Lookup From Training Data",
   "id": "44a4674ad890a16d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:59:47.970764Z",
     "start_time": "2026-02-16T23:59:47.915900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "price_data = []\n",
    "for _, row in train_df.iterrows():\n",
    "    try:\n",
    "        data = json.loads(row['expected_json'])\n",
    "        items = data.get('items', [])\n",
    "        total = data.get('total_price', 0)\n",
    "\n",
    "        if len(items) == 1 and items[0]['quantity'] == 1:\n",
    "            item = items[0]\n",
    "            price_data.append({\n",
    "                'name': item['name'],\n",
    "                'size': item.get('size'),\n",
    "                'modifiers': tuple(sorted(item.get('modifiers', []))),\n",
    "                'n_modifiers': len(item.get('modifiers', [])),\n",
    "                'price': total\n",
    "            })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "price_df = pd.DataFrame(price_data)\n",
    "\n",
    "# Base prices (no modifiers)\n",
    "base_prices = price_df[price_df['n_modifiers'] == 0].groupby(['name', 'size'])['price'].median().to_dict()\n",
    "\n",
    "# Modifier costs (relaxed threshold)\n",
    "with_mod = price_df[price_df['n_modifiers'] == 1]\n",
    "modifier_costs = {}\n",
    "for _, row in with_mod.iterrows():\n",
    "    base_key = (row['name'], row['size'])\n",
    "    if base_key in base_prices:\n",
    "        mod_cost = row['price'] - base_prices[base_key]\n",
    "        mod_name = row['modifiers'][0] if row['modifiers'] else None\n",
    "        if mod_name:\n",
    "            modifier_costs.setdefault(mod_name, []).append(mod_cost)\n",
    "\n",
    "avg_modifier_costs = {k: round(np.median(v), 2) for k, v in modifier_costs.items() if len(v) >= 1}\n",
    "\n",
    "# Also infer prices from multi-item orders to fill gaps\n",
    "for _, row in train_df.iterrows():\n",
    "    try:\n",
    "        data = json.loads(row['expected_json'])\n",
    "        items = data.get('items', [])\n",
    "        if len(items) >= 2:\n",
    "            known_total = 0\n",
    "            unknown = []\n",
    "            for item in items:\n",
    "                key = (item['name'], item.get('size'))\n",
    "                n_mods = len(item.get('modifiers', []))\n",
    "                mod_add = sum(avg_modifier_costs.get(m, 0.50) for m in item.get('modifiers', []))\n",
    "                if key in base_prices:\n",
    "                    known_total += (base_prices[key] + mod_add) * item['quantity']\n",
    "                else:\n",
    "                    unknown.append(item)\n",
    "            if len(unknown) == 1:\n",
    "                item = unknown[0]\n",
    "                mod_add = sum(avg_modifier_costs.get(m, 0.50) for m in item.get('modifiers', []))\n",
    "                inferred = (data['total_price'] - known_total) / item['quantity'] - mod_add\n",
    "                key = (item['name'], item.get('size'))\n",
    "                if 0.50 < inferred < 15.0:\n",
    "                    if key not in base_prices:\n",
    "                        base_prices[key] = round(inferred, 2)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"Base prices found: {len(base_prices)}\")\n",
    "for k, v in sorted(base_prices.items()):\n",
    "    print(f\"  {k}: ${v:.2f}\")\n",
    "print(f\"\\nModifier costs found: {len(avg_modifier_costs)}\")\n",
    "for k, v in sorted(avg_modifier_costs.items()):\n",
    "    print(f\"  {k}: ${v:.2f}\")"
   ],
   "id": "c6c168fef80bc2db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base prices found: 93\n",
      "  ('Americano', 'Grande'): $4.60\n",
      "  ('Americano', 'Short'): $4.20\n",
      "  ('Americano', 'Tall'): $4.00\n",
      "  ('Americano', 'Trenta'): $1.00\n",
      "  ('Americano', 'Venti'): $4.50\n",
      "  ('Avocado Toast', None): $7.00\n",
      "  ('Bacon Gouda Sandwich', None): $10.50\n",
      "  ('Bagel', None): $2.50\n",
      "  ('Blueberry Muffin', None): $7.75\n",
      "  ('Butter Croissant', None): $3.40\n",
      "  ('Cappuccino', 'Grande'): $7.25\n",
      "  ('Cappuccino', 'Short'): $3.43\n",
      "  ('Cappuccino', 'Tall'): $4.60\n",
      "  ('Cappuccino', 'Trenta'): $6.00\n",
      "  ('Cappuccino', 'Venti'): $5.50\n",
      "  ('Caramel Macchiato', 'Grande'): $5.75\n",
      "  ('Caramel Macchiato', 'Short'): $0.55\n",
      "  ('Caramel Macchiato', 'Tall'): $5.25\n",
      "  ('Caramel Macchiato', 'Trenta'): $7.25\n",
      "  ('Caramel Macchiato', 'Venti'): $6.25\n",
      "  ('Chai Latte', 'Grande'): $5.25\n",
      "  ('Chai Latte', 'Short'): $4.25\n",
      "  ('Chai Latte', 'Tall'): $4.78\n",
      "  ('Chai Latte', 'Trenta'): $6.25\n",
      "  ('Chai Latte', 'Venti'): $5.75\n",
      "  ('Cold Brew', 'Grande'): $4.75\n",
      "  ('Cold Brew', 'Short'): $4.28\n",
      "  ('Cold Brew', 'Tall'): $4.25\n",
      "  ('Cold Brew', 'Trenta'): $0.75\n",
      "  ('Cold Brew', 'Venti'): $3.78\n",
      "  ('Drip Coffee', 'Grande'): $3.00\n",
      "  ('Drip Coffee', 'Short'): $1.00\n",
      "  ('Drip Coffee', 'Tall'): $2.50\n",
      "  ('Drip Coffee', 'Trenta'): $4.00\n",
      "  ('Drip Coffee', 'Venti'): $3.50\n",
      "  ('Earl Grey Tea', 'Grande'): $8.61\n",
      "  ('Earl Grey Tea', 'Short'): $2.50\n",
      "  ('Earl Grey Tea', 'Tall'): $5.40\n",
      "  ('Earl Grey Tea', 'Trenta'): $4.35\n",
      "  ('Earl Grey Tea', 'Venti'): $4.00\n",
      "  ('Espresso', 'Grande'): $3.70\n",
      "  ('Espresso', 'Short'): $2.50\n",
      "  ('Espresso', 'Trenta'): $5.36\n",
      "  ('Espresso', 'Venti'): $4.50\n",
      "  ('Flat White', 'Grande'): $6.35\n",
      "  ('Flat White', 'Short'): $4.65\n",
      "  ('Flat White', 'Tall'): $4.85\n",
      "  ('Flat White', 'Trenta'): $7.00\n",
      "  ('Flat White', 'Venti'): $5.75\n",
      "  ('Frappe (Coffee)', 'Grande'): $4.55\n",
      "  ('Frappe (Coffee)', 'Short'): $5.00\n",
      "  ('Frappe (Coffee)', 'Tall'): $3.50\n",
      "  ('Frappe (Coffee)', 'Trenta'): $3.00\n",
      "  ('Frappe (Coffee)', 'Venti'): $6.60\n",
      "  ('Frappe (Mocha)', 'Grande'): $5.25\n",
      "  ('Frappe (Mocha)', 'Short'): $5.35\n",
      "  ('Frappe (Mocha)', 'Tall'): $5.85\n",
      "  ('Frappe (Mocha)', 'Trenta'): $7.25\n",
      "  ('Frappe (Mocha)', 'Venti'): $2.62\n",
      "  ('Green Tea', 'Grande'): $4.30\n",
      "  ('Green Tea', 'Short'): $2.30\n",
      "  ('Green Tea', 'Tall'): $3.00\n",
      "  ('Green Tea', 'Trenta'): $4.00\n",
      "  ('Green Tea', 'Venti'): $3.00\n",
      "  ('Hot Chocolate', 'Grande'): $4.50\n",
      "  ('Hot Chocolate', 'Short'): $5.75\n",
      "  ('Hot Chocolate', 'Tall'): $6.60\n",
      "  ('Hot Chocolate', 'Trenta'): $4.90\n",
      "  ('Hot Chocolate', 'Venti'): $5.30\n",
      "  ('Iced Coffee', 'Short'): $3.25\n",
      "  ('Iced Coffee', 'Tall'): $3.38\n",
      "  ('Iced Coffee', 'Trenta'): $4.50\n",
      "  ('Iced Coffee', 'Venti'): $4.00\n",
      "  ('Latte', 'Grande'): $1.90\n",
      "  ('Latte', 'Short'): $4.10\n",
      "  ('Latte', 'Tall'): $4.50\n",
      "  ('Latte', 'Trenta'): $6.00\n",
      "  ('Latte', 'Venti'): $4.97\n",
      "  ('Matcha Latte', 'Grande'): $5.85\n",
      "  ('Matcha Latte', 'Short'): $5.17\n",
      "  ('Matcha Latte', 'Tall'): $8.52\n",
      "  ('Matcha Latte', 'Trenta'): $1.65\n",
      "  ('Matcha Latte', 'Venti'): $6.35\n",
      "  ('Mocha', 'Grande'): $5.30\n",
      "  ('Mocha', 'Short'): $4.50\n",
      "  ('Mocha', 'Tall'): $12.46\n",
      "  ('Mocha', 'Trenta'): $4.28\n",
      "  ('Mocha', 'Venti'): $6.25\n",
      "  ('Strawberry Smoothie', 'Grande'): $6.50\n",
      "  ('Strawberry Smoothie', 'Short'): $3.60\n",
      "  ('Strawberry Smoothie', 'Tall'): $6.00\n",
      "  ('Strawberry Smoothie', 'Trenta'): $8.55\n",
      "  ('Strawberry Smoothie', 'Venti'): $7.00\n",
      "\n",
      "Modifier costs found: 2\n",
      "  Hazelnut Syrup: $0.50\n",
      "  No Ice: $0.00\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Build System Prompt With Menu Knowledge",
   "id": "ed3e379674584bb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T00:01:22.181230Z",
     "start_time": "2026-02-17T00:01:22.130052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "menu_str = \"BASE PRICES (name, size): price\\n\"\n",
    "for (name, size), price in sorted(base_prices.items()):\n",
    "    menu_str += f\"  {name}, {size}: ${price:.2f}\\n\"\n",
    "\n",
    "modifier_str = \"MODIFIER COSTS:\\n\"\n",
    "for mod, cost in sorted(avg_modifier_costs.items()):\n",
    "    modifier_str += f\"  {mod}: ${cost:.2f}\\n\"\n",
    "\n",
    "# Few-shot examples from training\n",
    "example_indices = train_df.sample(n=min(10, len(train_df)), random_state=42).index\n",
    "examples_str = \"\"\n",
    "text_col = [c for c in train_df.columns if c not in ('id', 'expected_json')][0]\n",
    "for i, idx in enumerate(example_indices):\n",
    "    row = train_df.loc[idx]\n",
    "    examples_str += f\"\\nExample {i+1}:\\nOrder: {row[text_col]}\\nOutput: {row['expected_json']}\\n\"\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"You are a barista order parser. Given a natural language coffee shop order, extract the structured order as JSON.\n",
    "\n",
    "RULES:\n",
    "- Parse each item with: name, size (null for food items), quantity, modifiers (list, empty if none)\n",
    "- Handle corrections: \"actually\", \"no make it\", \"cancel that\", \"remove that\", \"nevermind\" mean to undo the previous modifier or item\n",
    "- Ignore filler words: \"literally\", \"like\", \"um\", \"actually\" (when not used for corrections)\n",
    "- Sizes: Short, Tall, Grande, Venti, Trenta (normalize to title case)\n",
    "- Quantity words: single/a/one=1, pair/couple/double/two=2, triple/three=3, four=4, five=5\n",
    "- Calculate total_price based on the menu prices below\n",
    "- Food items (Toast, Bagel, Croissant, Sandwich, Muffin, Cookie, Cake Pop, etc.) have size: null\n",
    "- Modifier names should be in Title Case\n",
    "\n",
    "{menu_str}\n",
    "{modifier_str}\n",
    "\n",
    "IMPORTANT: Respond with ONLY valid JSON. No markdown, no explanation, no code fences. Format:\n",
    "{{\"items\": [{{\"name\": \"...\", \"size\": \"...\" or null, \"quantity\": N, \"modifiers\": [...]}}], \"total_price\": X.XX}}\n",
    "\n",
    "{examples_str}\"\"\""
   ],
   "id": "8f29410f8a51c6a6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Parse Test Orders Using Gemini",
   "id": "9ccf87eb69166ba9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T06:56:52.179304Z",
     "start_time": "2026-02-17T01:05:13.912287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyA_e0KQ-mTBsJ73_qCuLnuXvpVuv7V-C5k\")  # your actual key\n",
    "\n",
    "MAX_WORKERS = 10\n",
    "MAX_RETRIES = 3\n",
    "RATE_LIMIT_DELAY = 0.2\n",
    "\n",
    "thread_local = threading.local()\n",
    "rate_lock = threading.Lock()\n",
    "last_request_time = [0.0]\n",
    "\n",
    "def get_model():\n",
    "    if not hasattr(thread_local, 'model'):\n",
    "        thread_local.model = genai.GenerativeModel(\n",
    "            'gemini-2.5-flash-lite',          # updated model\n",
    "            system_instruction=SYSTEM_PROMPT,\n",
    "            generation_config=genai.GenerationConfig(\n",
    "                temperature=0.0,\n",
    "                max_output_tokens=1024,\n",
    "            )\n",
    "        )\n",
    "    return thread_local.model\n",
    "\n",
    "def rate_limited_wait():\n",
    "    \"\"\"Ensure minimum delay between API calls globally.\"\"\"\n",
    "    with rate_lock:\n",
    "        now = time.time()\n",
    "        wait = RATE_LIMIT_DELAY - (now - last_request_time[0])\n",
    "        if wait > 0:\n",
    "            time.sleep(wait)\n",
    "        last_request_time[0] = time.time()\n",
    "\n",
    "def parse_order(order_text):\n",
    "    model = get_model()\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            rate_limited_wait()\n",
    "            response = model.generate_content(f\"Parse this order:\\n{order_text}\")\n",
    "            result_text = response.text.strip()\n",
    "            result_text = result_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "            parsed = json.loads(result_text)\n",
    "            if 'items' not in parsed or 'total_price' not in parsed:\n",
    "                raise ValueError(\"Missing required keys\")\n",
    "            return parsed\n",
    "\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                time.sleep(2)\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            err_str = str(e).lower()\n",
    "            if 'rate' in err_str or '429' in err_str:\n",
    "                time.sleep(10 * (attempt + 1))  # back off hard on rate limits\n",
    "            elif attempt < MAX_RETRIES - 1:\n",
    "                time.sleep(3 ** (attempt + 1))\n",
    "            continue\n",
    "\n",
    "    return {\"items\": [], \"total_price\": 0.0}\n",
    "\n",
    "def parse_order_with_index(args):\n",
    "    idx, order_text = args\n",
    "    parsed = parse_order(order_text)\n",
    "    return idx, json.dumps(parsed)\n",
    "\n",
    "print(f\"\\nParsing {len(test_df)} test orders with {MAX_WORKERS} workers...\")\n",
    "\n",
    "tasks = [(idx, row[text_col]) for idx, row in test_df.iterrows()]\n",
    "results_dict = {}\n",
    "failed = 0\n",
    "start_time = time.time()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(parse_order_with_index, task): task[0] for task in tasks}\n",
    "\n",
    "    with tqdm(total=len(tasks), desc=\"Parsing orders\", unit=\"order\",\n",
    "              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:\n",
    "        for future in as_completed(futures):\n",
    "            idx, result_json = future.result()\n",
    "            results_dict[idx] = result_json\n",
    "\n",
    "            parsed = json.loads(result_json)\n",
    "            if len(parsed.get('items', [])) == 0:\n",
    "                failed += 1\n",
    "\n",
    "            pbar.set_postfix(failed=failed)\n",
    "            pbar.update(1)\n",
    "\n",
    "results = [results_dict[idx] for idx in test_df.index]\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nDone! {len(results)} orders in {elapsed:.1f}s ({failed} failed)\")"
   ],
   "id": "f1e672d093805927",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing 3500 test orders with 10 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing orders: 100%|██████████| 3500/3500 [5:51:38<00:00,  6.03s/order]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! 3500 orders in 21098.1s (3498 failed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6. Generate Submission",
   "id": "eeb1f86334e959f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T08:30:05.200946Z",
     "start_time": "2026-02-17T08:30:05.074161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'predicted_json': results\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"\\nSubmission saved! Shape: {submission.shape}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(min(5, len(submission))):\n",
    "    print(f\"\\n  ID {submission.iloc[i]['id']}:\")\n",
    "    print(f\"  {submission.iloc[i]['predicted_json']}\")"
   ],
   "id": "f0ca4c616e546b41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission saved! Shape: (3500, 2)\n",
      "\n",
      "Sample predictions:\n",
      "\n",
      "  ID 500:\n",
      "  {\"items\": [], \"total_price\": 0.0}\n",
      "\n",
      "  ID 501:\n",
      "  {\"items\": [], \"total_price\": 0.0}\n",
      "\n",
      "  ID 502:\n",
      "  {\"items\": [], \"total_price\": 0.0}\n",
      "\n",
      "  ID 503:\n",
      "  {\"items\": [], \"total_price\": 0.0}\n",
      "\n",
      "  ID 504:\n",
      "  {\"items\": [], \"total_price\": 0.0}\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
